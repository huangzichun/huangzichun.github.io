---
layout:     post
title:      贝叶斯机器学习入坑指南
subtitle:   又是一个磨人的笔记
date:       2021-12-20
author:     HC
header-img: img/post-sample-image.jpg
catalog: true
tags:
    - 贝叶斯机器学习
    - Bayesian Machine Learning
---



# 0x00 说在前面的话

入坑贝叶斯机器学习，说不定之后会用到，特地来总结一下学习笔记。



# 0x01 贝叶斯机器学习的基本组件

贝叶斯机器学习最基本的组件有四个，包括似然（Likelihood）、先验（Prior）、后验（Posterior）和推理（Inference）。

- **似然 $P(D|\theta)$**：表示在给定参数$\theta$的情况下，描述已观测数据的生成机制。在这组$\theta$参数下，生成当前的观测数据的可能性有多大
- **先验$P(\theta)$**：表示对参数$\theta$的初始知识，是在观测到数据之前的参数分布。比如我们会认为掷硬币正面向上的概率是1/2
- **后验$P(\theta|D)$**：表示在给定观测数据后，通过数据得到了更多关于参数的知识，是参数的事后分布。通常用贝叶斯公式计算得到
- **推断（Inference）**：一般表示用后验分布进行的分析，包括
  - 点估计：最"好"的一个$\theta$值是多少 （好的定义由loss function决定）
  - 做预测："遍历"参数的后验分布取值，模型在不同参数下的预测结果的均值
  - 做决策：能最小化后验损失的参数是多少
  - 贝叶斯模型选择（Bayesian Model Comparison）
  - 等等



# 0x02 贝叶斯机器学习都在干啥

## 2.1 难在哪里

贝叶斯机器学习的关注对象是先验分布、似然和后验分布，其中

1. **难点一：先验分布如何选择**

   > 参数的先验知识从何而来？选哪种分布更方面我们计算后验分布？

2. **难点二：参数后验分布太难解**

   > 贝叶斯公式用来求后验分布的时候，分布的积分太难求解了
   >
   >  
   > $$
   > P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}= \frac{P(D|\theta)P(\theta)}{\int P(D|\theta)P(\theta) d\theta}
   > $$
   >  
   >
   > 



## 2.2 推理算法

贝叶斯机器学习为了要用后验分布，就需要解决积分问题。所以，贝叶斯机器学习干的事之一就是参数后验分布的求解啦。至今，已经有很多的算法来求解，包括

1. **MAP（Maximum A Posterior，最大后验估计）**：用点估计来近似，将积分问题，转化成求最大值的问题
2. **Gibbs采样/MCMC**：一种基于蒙特卡洛采样的算法，用序列化采样得到的样本来近似估计后验分布
3. **变分推断（Variational Inference）**：旨在将复杂的后验分布，用另一个简单的分布来近似，并用这个近似分布来代替原后验分布。



## 2.3 应用例子

贝叶斯机器学习在求解了参数后验分布之后，就开始了一大推的应用，包括

1. 常见模型：Factor Analysis / HMM / Bayesian Linear regression / Bayesian nets / Latent dirichlet allocation / NMF / probabilistic latent semantic analysis / Linear dynamical system / sparse coding / ICA等等
2. 贝叶斯无参模型（Bayesian Nonparametrics，不是没有参数，而是无穷参数）：Gaussian Process / Dirichlet process / hierarchical Dirichlet process / Indian buffet process / IBP linear-Gaussian model / beta process / Dirichlet diffusion trees / Pitman-Yor process
3. 采样算法 与 变分推断
4. 信念传播（Belief propagation）
5. 等等

 



**TODO**





# 0x03 贝叶斯决策理论 (Decision Theory)



# 0x04 贝叶斯模型选择



# 0x05 Bayesian Logistic Regression



# 0x06 Gaussian Process Regression



# 0x07 Bayesian Quadrature



# 0x08 Gaussian Process Classification



# 0x09 Bayesian Optimization



# 0x10 Sampling



# 0x11 Variational Inference



# 0x12 Dynamical Systems





